from copy import deepcopy
from typing import Tuple

import streamlit as st
from langchain.chat_models import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage, SystemMessage
from openai_api_cost_handler import StreamlitCostCalcHandler, TokenCostProcess


def init_page() -> None:
    st.set_page_config(page_title="My Great ChatGPT", page_icon="ğŸ¤—")
    st.header("My Great ChatGPT ğŸ¤—")
    st.sidebar.title("Options")


def init_messages() -> None:
    clear_button = st.sidebar.button("Clear Conversation", key="clear")
    if clear_button or "messages" not in st.session_state:
        st.session_state.messages = [SystemMessage(content="You are a helpful assistant.")]
        st.session_state.costs = []


def select_model() -> Tuple[ChatOpenAI, str]:
    model = st.sidebar.radio("Choose a model:", ("GPT-3.5", "GPT-4"))
    if model == "GPT-3.5":
        model_name = "gpt-3.5-turbo"
    else:
        model_name = "gpt-4"

    # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’è¿½åŠ ã—ã€temperatureã‚’0ã‹ã‚‰2ã¾ã§ã®ç¯„å›²ã§é¸æŠå¯èƒ½ã«ã™ã‚‹
    # åˆæœŸå€¤ã¯0.0ã€åˆ»ã¿å¹…ã¯0.1ã¨ã™ã‚‹
    temperature = st.sidebar.slider("Temperature:", min_value=0.0, max_value=2.0, value=0.0, step=0.01)

    llm = ChatOpenAI(  # type: ignore
        temperature=temperature,
        model_name=model_name,
        streaming=True,
    )
    return llm, model_name


def main() -> None:
    init_page()

    llm, model_name = select_model()
    init_messages()

    container = st.container()

    # ã‚³ã‚¹ãƒˆã®å–å¾—
    costs = deepcopy(st.session_state.get("costs", []))

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    messages = st.session_state.get("messages", [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)
                # ã‚³ã‚¹ãƒˆè¡¨ç¤º
                st.markdown(f"cost: ${costs.pop(0):.5f}")
        elif isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        else:  # isinstance(message, SystemMessage):
            st.write(f"System message: {message.content}")

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    with container:
        with st.form(key="my_form", clear_on_submit=True):
            user_input = st.text_area(label="Message: ", key="input", height=100)
            submit_button = st.form_submit_button(label="Send")

    # NOTE: streamlit 1.26.0 å¾…ã¡
    # if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
    if submit_button and user_input:
        st.session_state.messages.append(HumanMessage(content=user_input))
        # streamingè¡¨ç¤º
        st.chat_message("user").markdown(user_input)
        with st.chat_message("assistant"):
            token_cost_process = TokenCostProcess(model_name)
            st_callback = StreamlitCostCalcHandler(st.container(), token_cost_process)
            answer = llm(messages, callbacks=[st_callback]).content
            cost = token_cost_process.total_cost
            st.markdown(f"cost: ${cost:.5f}")
        st.session_state.messages.append(AIMessage(content=answer))
        st.session_state.costs.append(cost)
        # ã‚³ã‚¹ãƒˆã®å†å–å¾—ã€è¡¨ç¤º
        costs = deepcopy(st.session_state.get("costs", []))
        st.sidebar.markdown("## Costs")
        st.sidebar.markdown(f"**Total cost: ${sum(costs):.5f}**")


if __name__ == "__main__":
    main()
