from copy import deepcopy
from typing import Tuple

import streamlit as st
from chatgpt_app.openai_api_cost_handler import StreamlitCostCalcHandler, TokenCostProcess
from chatgpt_app.pages.base import BasePage
from chatgpt_app.session import StreamlistSessionManager
from langchain.chat_models import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage, SystemMessage


def init_page() -> None:
    st.set_page_config(page_title="My Great ChatGPT", page_icon="ğŸ¤—")
    st.header("My Great ChatGPT ğŸ¤—")
    st.sidebar.title("Options")


def init_messages(sm: StreamlistSessionManager) -> None:
    clear_button = st.sidebar.button("Clear Conversation", key="clear")
    if clear_button or len(sm.get_messages()) == 0:
        sm.clear_messages()
        sm.clear_costs()
        sm.add_message(SystemMessage(content="You are a helpful assistant."))


def select_model() -> Tuple[ChatOpenAI, str]:
    model = st.sidebar.radio("Choose a model:", ("GPT-3.5", "GPT-4"))
    if model == "GPT-3.5":
        model_name = "gpt-3.5-turbo"
    else:
        model_name = "gpt-4"

    # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’è¿½åŠ ã—ã€temperatureã‚’0ã‹ã‚‰2ã¾ã§ã®ç¯„å›²ã§é¸æŠå¯èƒ½ã«ã™ã‚‹
    # åˆæœŸå€¤ã¯0.0ã€åˆ»ã¿å¹…ã¯0.1ã¨ã™ã‚‹
    temperature = st.sidebar.slider("Temperature:", min_value=0.0, max_value=2.0, value=0.0, step=0.01)

    llm = ChatOpenAI(  # type: ignore
        temperature=temperature,
        model_name=model_name,
        streaming=True,
    )
    return llm, model_name


class ChatBotPage(BasePage):
    def render(self) -> None:
        init_page()

        llm, model_name = select_model()
        init_messages(self.sm)

        container = st.container()

        # ã‚³ã‚¹ãƒˆã®å–å¾—
        costs = deepcopy(self.sm.get_costs())

        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
        messages = self.sm.get_messages()
        for message in messages:
            if isinstance(message, AIMessage):
                with st.chat_message("assistant"):
                    st.markdown(message.content)
                    # ã‚³ã‚¹ãƒˆè¡¨ç¤º
                    st.markdown(f"cost: ${costs.pop(0):.5f}")
            elif isinstance(message, HumanMessage):
                with st.chat_message("user"):
                    st.markdown(message.content)
            else:  # isinstance(message, SystemMessage):
                st.write(f"System message: {message.content}")

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
        with container:
            with st.form(key="my_form", clear_on_submit=True):
                user_input = st.text_area(label="Message: ", key="input", height=100)
                submit_button = st.form_submit_button(label="Send")

        # NOTE: streamlit 1.26.0 å¾…ã¡
        # if user_input := st.chat_input("èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­ï¼"):
        if submit_button and user_input:
            self.sm.add_message(HumanMessage(content=user_input))
            # streamingè¡¨ç¤º
            st.chat_message("user").markdown(user_input)
            with st.chat_message("assistant"):
                token_cost_process = TokenCostProcess(model_name)
                st_callback = StreamlitCostCalcHandler(st.container(), token_cost_process)
                answer = llm(messages, callbacks=[st_callback]).content
                cost = token_cost_process.total_cost
                st.markdown(f"cost: ${cost:.5f}")
            self.sm.add_message(AIMessage(content=answer))
            self.sm.add_cost(cost)
            # ã‚³ã‚¹ãƒˆã®å†å–å¾—ã€è¡¨ç¤º
            st.sidebar.markdown("## Costs")
            st.sidebar.markdown(f"**Total cost: ${sum(self.sm.get_costs()):.5f}**")
